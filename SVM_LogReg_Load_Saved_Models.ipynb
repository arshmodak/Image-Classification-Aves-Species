{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading best performing SVM model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    }
   ],
   "source": [
    "clf = pickle.load(open('svm_model_0.7.sav' , 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading saved testing and training features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load('X_test_7_7_512.npy')\n",
    "Y_test = np.load('Y_test.npy')\n",
    "Y_train = np.load('Y_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy of SVM model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8915555555555555\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test , pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading best performing Logistic Regression model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf1 = pickle.load(open('svm_model_logreg.sav' , 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = clf1.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy of Logistic Regression model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8506666666666667\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test , pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification report for each class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89         5\n",
      "           1       1.00      1.00      1.00         5\n",
      "           2       0.67      0.80      0.73         5\n",
      "           3       1.00      1.00      1.00         5\n",
      "           4       1.00      0.60      0.75         5\n",
      "           5       1.00      0.80      0.89         5\n",
      "           6       0.80      0.80      0.80         5\n",
      "           7       0.67      0.80      0.73         5\n",
      "           8       1.00      0.80      0.89         5\n",
      "           9       0.60      0.60      0.60         5\n",
      "          10       0.75      0.60      0.67         5\n",
      "          11       0.83      1.00      0.91         5\n",
      "          12       0.67      0.80      0.73         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "          14       0.75      0.60      0.67         5\n",
      "          15       1.00      0.80      0.89         5\n",
      "          16       1.00      1.00      1.00         5\n",
      "          17       1.00      0.80      0.89         5\n",
      "          18       0.67      0.40      0.50         5\n",
      "          19       1.00      1.00      1.00         5\n",
      "          20       0.80      0.80      0.80         5\n",
      "          21       0.80      0.80      0.80         5\n",
      "          22       1.00      1.00      1.00         5\n",
      "          23       0.75      0.60      0.67         5\n",
      "          24       0.83      1.00      0.91         5\n",
      "          25       1.00      1.00      1.00         5\n",
      "          26       1.00      0.80      0.89         5\n",
      "          27       0.56      1.00      0.71         5\n",
      "          28       0.75      0.60      0.67         5\n",
      "          29       1.00      1.00      1.00         5\n",
      "          30       0.67      0.80      0.73         5\n",
      "          31       0.60      0.60      0.60         5\n",
      "          32       1.00      0.80      0.89         5\n",
      "          33       0.83      1.00      0.91         5\n",
      "          34       0.83      1.00      0.91         5\n",
      "          35       1.00      0.80      0.89         5\n",
      "          36       0.83      1.00      0.91         5\n",
      "          37       1.00      0.20      0.33         5\n",
      "          38       0.75      0.60      0.67         5\n",
      "          39       0.67      0.80      0.73         5\n",
      "          40       1.00      1.00      1.00         5\n",
      "          41       1.00      0.80      0.89         5\n",
      "          42       1.00      1.00      1.00         5\n",
      "          43       0.80      0.80      0.80         5\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       0.62      1.00      0.77         5\n",
      "          46       0.83      1.00      0.91         5\n",
      "          47       0.75      0.60      0.67         5\n",
      "          48       1.00      0.80      0.89         5\n",
      "          49       0.80      0.80      0.80         5\n",
      "          50       1.00      0.80      0.89         5\n",
      "          51       0.60      0.60      0.60         5\n",
      "          52       0.57      0.80      0.67         5\n",
      "          53       0.83      1.00      0.91         5\n",
      "          54       0.83      1.00      0.91         5\n",
      "          55       0.71      1.00      0.83         5\n",
      "          56       1.00      1.00      1.00         5\n",
      "          57       0.80      0.80      0.80         5\n",
      "          58       0.57      0.80      0.67         5\n",
      "          59       1.00      1.00      1.00         5\n",
      "          60       1.00      1.00      1.00         5\n",
      "          61       0.83      1.00      0.91         5\n",
      "          62       0.75      0.60      0.67         5\n",
      "          63       0.80      0.80      0.80         5\n",
      "          64       1.00      0.80      0.89         5\n",
      "          65       0.25      0.20      0.22         5\n",
      "          66       1.00      0.80      0.89         5\n",
      "          67       1.00      1.00      1.00         5\n",
      "          68       0.83      1.00      0.91         5\n",
      "          69       0.71      1.00      0.83         5\n",
      "          70       0.50      0.60      0.55         5\n",
      "          71       1.00      0.80      0.89         5\n",
      "          72       1.00      0.80      0.89         5\n",
      "          73       1.00      1.00      1.00         5\n",
      "          74       1.00      0.80      0.89         5\n",
      "          75       0.75      0.60      0.67         5\n",
      "          76       1.00      0.80      0.89         5\n",
      "          77       1.00      0.80      0.89         5\n",
      "          78       0.71      1.00      0.83         5\n",
      "          79       1.00      1.00      1.00         5\n",
      "          80       1.00      1.00      1.00         5\n",
      "          81       1.00      0.80      0.89         5\n",
      "          82       0.62      1.00      0.77         5\n",
      "          83       1.00      1.00      1.00         5\n",
      "          84       1.00      1.00      1.00         5\n",
      "          85       0.80      0.80      0.80         5\n",
      "          86       1.00      0.80      0.89         5\n",
      "          87       0.67      0.80      0.73         5\n",
      "          88       0.83      1.00      0.91         5\n",
      "          89       0.71      1.00      0.83         5\n",
      "          90       0.67      0.80      0.73         5\n",
      "          91       0.83      1.00      0.91         5\n",
      "          92       1.00      0.80      0.89         5\n",
      "          93       0.83      1.00      0.91         5\n",
      "          94       1.00      1.00      1.00         5\n",
      "          95       1.00      1.00      1.00         5\n",
      "          96       0.80      0.80      0.80         5\n",
      "          97       1.00      0.80      0.89         5\n",
      "          98       0.83      1.00      0.91         5\n",
      "          99       1.00      1.00      1.00         5\n",
      "         100       0.83      1.00      0.91         5\n",
      "         101       0.62      1.00      0.77         5\n",
      "         102       1.00      1.00      1.00         5\n",
      "         103       1.00      1.00      1.00         5\n",
      "         104       1.00      0.80      0.89         5\n",
      "         105       0.83      1.00      0.91         5\n",
      "         106       1.00      0.60      0.75         5\n",
      "         107       0.60      0.60      0.60         5\n",
      "         108       1.00      1.00      1.00         5\n",
      "         109       1.00      1.00      1.00         5\n",
      "         110       0.80      0.80      0.80         5\n",
      "         111       0.67      0.40      0.50         5\n",
      "         112       0.83      1.00      0.91         5\n",
      "         113       1.00      1.00      1.00         5\n",
      "         114       0.50      0.80      0.62         5\n",
      "         115       1.00      1.00      1.00         5\n",
      "         116       1.00      1.00      1.00         5\n",
      "         117       1.00      1.00      1.00         5\n",
      "         118       1.00      0.60      0.75         5\n",
      "         119       0.80      0.80      0.80         5\n",
      "         120       1.00      1.00      1.00         5\n",
      "         121       0.67      0.80      0.73         5\n",
      "         122       0.80      0.80      0.80         5\n",
      "         123       0.80      0.80      0.80         5\n",
      "         124       1.00      0.80      0.89         5\n",
      "         125       1.00      0.80      0.89         5\n",
      "         126       1.00      1.00      1.00         5\n",
      "         127       1.00      1.00      1.00         5\n",
      "         128       1.00      1.00      1.00         5\n",
      "         129       1.00      0.80      0.89         5\n",
      "         130       1.00      0.80      0.89         5\n",
      "         131       0.83      1.00      0.91         5\n",
      "         132       0.67      0.80      0.73         5\n",
      "         133       0.67      0.80      0.73         5\n",
      "         134       1.00      0.60      0.75         5\n",
      "         135       0.83      1.00      0.91         5\n",
      "         136       1.00      1.00      1.00         5\n",
      "         137       1.00      0.60      0.75         5\n",
      "         138       1.00      0.80      0.89         5\n",
      "         139       0.75      0.60      0.67         5\n",
      "         140       0.67      0.40      0.50         5\n",
      "         141       0.67      0.80      0.73         5\n",
      "         142       0.60      0.60      0.60         5\n",
      "         143       1.00      0.80      0.89         5\n",
      "         144       1.00      0.80      0.89         5\n",
      "         145       1.00      0.60      0.75         5\n",
      "         146       1.00      0.60      0.75         5\n",
      "         147       1.00      0.60      0.75         5\n",
      "         148       1.00      1.00      1.00         5\n",
      "         149       1.00      1.00      1.00         5\n",
      "         150       1.00      1.00      1.00         5\n",
      "         151       1.00      1.00      1.00         5\n",
      "         152       0.71      1.00      0.83         5\n",
      "         153       1.00      0.80      0.89         5\n",
      "         154       0.80      0.80      0.80         5\n",
      "         155       0.67      0.80      0.73         5\n",
      "         156       1.00      1.00      1.00         5\n",
      "         157       1.00      1.00      1.00         5\n",
      "         158       0.83      1.00      0.91         5\n",
      "         159       0.75      0.60      0.67         5\n",
      "         160       0.67      0.40      0.50         5\n",
      "         161       0.67      0.80      0.73         5\n",
      "         162       0.43      0.60      0.50         5\n",
      "         163       1.00      1.00      1.00         5\n",
      "         164       1.00      1.00      1.00         5\n",
      "         165       0.80      0.80      0.80         5\n",
      "         166       0.80      0.80      0.80         5\n",
      "         167       1.00      1.00      1.00         5\n",
      "         168       1.00      1.00      1.00         5\n",
      "         169       1.00      0.80      0.89         5\n",
      "         170       0.62      1.00      0.77         5\n",
      "         171       1.00      1.00      1.00         5\n",
      "         172       0.71      1.00      0.83         5\n",
      "         173       1.00      0.60      0.75         5\n",
      "         174       1.00      0.80      0.89         5\n",
      "         175       0.80      0.80      0.80         5\n",
      "         176       0.83      1.00      0.91         5\n",
      "         177       0.67      0.80      0.73         5\n",
      "         178       0.80      0.80      0.80         5\n",
      "         179       0.83      1.00      0.91         5\n",
      "         180       1.00      0.80      0.89         5\n",
      "         181       0.83      1.00      0.91         5\n",
      "         182       0.80      0.80      0.80         5\n",
      "         183       1.00      0.60      0.75         5\n",
      "         184       1.00      1.00      1.00         5\n",
      "         185       1.00      1.00      1.00         5\n",
      "         186       1.00      0.80      0.89         5\n",
      "         187       0.83      1.00      0.91         5\n",
      "         188       1.00      1.00      1.00         5\n",
      "         189       0.83      1.00      0.91         5\n",
      "         190       0.83      1.00      0.91         5\n",
      "         191       1.00      1.00      1.00         5\n",
      "         192       1.00      0.60      0.75         5\n",
      "         193       1.00      1.00      1.00         5\n",
      "         194       0.80      0.80      0.80         5\n",
      "         195       1.00      1.00      1.00         5\n",
      "         196       0.80      0.80      0.80         5\n",
      "         197       1.00      1.00      1.00         5\n",
      "         198       1.00      1.00      1.00         5\n",
      "         199       1.00      1.00      1.00         5\n",
      "         200       0.83      1.00      0.91         5\n",
      "         201       1.00      0.60      0.75         5\n",
      "         202       1.00      1.00      1.00         5\n",
      "         203       1.00      1.00      1.00         5\n",
      "         204       0.67      0.80      0.73         5\n",
      "         205       1.00      1.00      1.00         5\n",
      "         206       1.00      0.60      0.75         5\n",
      "         207       0.67      0.80      0.73         5\n",
      "         208       0.75      0.60      0.67         5\n",
      "         209       0.60      0.60      0.60         5\n",
      "         210       0.83      1.00      0.91         5\n",
      "         211       1.00      1.00      1.00         5\n",
      "         212       0.83      1.00      0.91         5\n",
      "         213       0.80      0.80      0.80         5\n",
      "         214       0.83      1.00      0.91         5\n",
      "         215       0.83      1.00      0.91         5\n",
      "         216       1.00      1.00      1.00         5\n",
      "         217       1.00      0.60      0.75         5\n",
      "         218       0.75      0.60      0.67         5\n",
      "         219       0.71      1.00      0.83         5\n",
      "         220       0.71      1.00      0.83         5\n",
      "         221       0.83      1.00      0.91         5\n",
      "         222       0.67      0.80      0.73         5\n",
      "         223       1.00      1.00      1.00         5\n",
      "         224       1.00      0.60      0.75         5\n",
      "\n",
      "    accuracy                           0.85      1125\n",
      "   macro avg       0.87      0.85      0.85      1125\n",
      "weighted avg       0.87      0.85      0.85      1125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test , pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
